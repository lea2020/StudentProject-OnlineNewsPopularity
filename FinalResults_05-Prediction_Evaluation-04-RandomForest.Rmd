---
title: "FinalResults_05-Prediction_Evaluation-04-RandomForest"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Predicting Online News Popularity based on Pre-publication Features

Final Results and Code


Step 5 - Prediction & Step 6 - Performance Evaluation

Prediction: Classification models - Logistic Regression, K-Nearest Neighbours, Decision Trees, Random Forest, and Gradient Boosting Machine - are tested to find the algorithm with the best accuracy. 

Performance Evaluation: At this stage, the machine learning algorithms that have been run are evaluated using various methods. Several metrics are computed including Accuracy, Precision, Recall/Sensitivity, Specificity, and F1, depending on the Confusion Matrix. 

Note the results found are similar to what has been found in the literature.


Random Forest

```{r }
#Reload the data
train.set <- read.csv(file = "trainset.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, 
                      na.strings = c("", "NA"))

valid.set <- read.csv(file = "validset.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, 
                      na.strings = c("", "NA"))

test.set <- read.csv(file = "testset.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, 
                     na.strings = c("", "NA"))

train <- read.csv(file = "train.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, 
                  na.strings = c("", "NA"))

test <- read.csv(file = "test.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, 
                 na.strings = c("", "NA"))

#Remove the index column
train.set <- train.set[2:28]
valid.set <- valid.set[2:28]
test.set <- test.set[2:28]
train <- train[2:28]
test <- test[2:28]
```

```{r }
#Change the categorical variables back to factor to conduct model training and testing
train.set$data_channel_is_entertainment <- as.factor(train.set$data_channel_is_entertainment)
train.set$data_channel_is_socmed <- as.factor(train.set$data_channel_is_socmed)
train.set$weekday_is_saturday <- as.factor(train.set$weekday_is_saturday)
train.set$weekday_is_sunday <- as.factor(train.set$weekday_is_sunday)
train.set$shares_cat <- as.factor(train.set$shares_cat)

valid.set$data_channel_is_entertainment <- as.factor(valid.set$data_channel_is_entertainment)
valid.set$data_channel_is_socmed <- as.factor(valid.set$data_channel_is_socmed)
valid.set$weekday_is_saturday <- as.factor(valid.set$weekday_is_saturday)
valid.set$weekday_is_sunday <- as.factor(valid.set$weekday_is_sunday)
valid.set$shares_cat <- as.factor(valid.set$shares_cat)

test.set$data_channel_is_entertainment <- as.factor(test.set$data_channel_is_entertainment)
test.set$data_channel_is_socmed <- as.factor(test.set$data_channel_is_socmed)
test.set$weekday_is_saturday <- as.factor(test.set$weekday_is_saturday)
test.set$weekday_is_sunday <- as.factor(test.set$weekday_is_sunday)
test.set$shares_cat <- as.factor(test.set$shares_cat)

train$data_channel_is_entertainment <- as.factor(train$data_channel_is_entertainment)
train$data_channel_is_socmed <- as.factor(train$data_channel_is_socmed)
train$weekday_is_saturday <- as.factor(train$weekday_is_saturday)
train$weekday_is_sunday <- as.factor(train$weekday_is_sunday)
train$shares_cat <- as.factor(train$shares_cat)

test$data_channel_is_entertainment <- as.factor(test$data_channel_is_entertainment)
test$data_channel_is_socmed <- as.factor(test$data_channel_is_socmed)
test$weekday_is_saturday <- as.factor(test$weekday_is_saturday)
test$weekday_is_sunday <- as.factor(test$weekday_is_sunday)
test$shares_cat <- as.factor(test$shares_cat)
```

```{r }
#Tune the model based on the mtry parameter - number of variables randomly sampled as candidates at each split
library(caret)
set.seed(123)
rffit <- train(shares_cat ~., data = train.set, method = "rf", tuneLength = 3, 
               trControl = trainControl(method = "cv", search = "grid"))

#Print the training model to see the accuracy
print(rffit)
```

```{r }
#Plot the results
#Visualize the accuracy based on the value of mtry.
plot(rffit)
```

```{r }
#Create a Random Forest model using the validation set with mtry = 2
library(randomForest)
set.seed(123)
rf_model <- randomForest(shares_cat ~., data = valid.set, mtry = 2, importance = TRUE)

#Print the model
print(rf_model)
```

```{r }
#Plot the results
plot(rf_model)
```

```{r }
#Make a prediction on the test set
rf_predict <- predict(rf_model, test.set, type = "class")

#Confusion Matrix and Statistics
rf_confusionMatrix_stats <- confusionMatrix(rf_predict, test.set$shares_cat, mode = "everything", positive = "1")
print(rf_confusionMatrix_stats)
```


Using 10-fold cross-validation

```{r }
#Create a random forest model with mtry = 2
set.seed(123)
rf_model2 <- randomForest(shares_cat ~., data = train, mtry = 2, importance = TRUE)

#Print the model
print(rf_model2)
```

```{r }
#Plot the results
plot(rf_model2)
```

```{r }
#Check the important variables
set.seed(123)
importance(rf_model2)
```

```{r }
#Evaluate variable importance according to mean decrease in accuracy and mean decrease in gini
#Mean Decrease in Accuracy
set.seed(123)
rf_imp_class2 = importance(rf_model2, type=1)
rf_imp_class2 <- data.frame(predictors=rownames(rf_imp_class2),rf_imp_class2)

#Mean Decrease Gini
set.seed(123)
rf_imp_gini2 = importance(rf_model2, type=2)
rf_imp_gini2 <- data.frame(predictors=rownames(rf_imp_gini2),rf_imp_gini2)

#Order the predictors by importance according to Mean Decrease in Accuracy
library(dplyr)
rf_imp_class2.sort <- arrange(rf_imp_class2, desc(MeanDecreaseAccuracy))
rf_imp_class2.sort$predictors <- factor(rf_imp_class2.sort$predictors,levels=rf_imp_class2.sort$predictors)

#Print the predictors sorted by Mean Decrease in Accuracy
print(rf_imp_class2.sort)
```

```{r }
#Order the predictors by importance according to Mean Decrease in Gini
rf_imp_gini2.sort <- arrange(rf_imp_gini2, desc(rf_imp_gini2$MeanDecreaseGini))
rf_imp_gini2.sort$predictors <- factor(rf_imp_gini2.sort$predictors,levels=rf_imp_gini2.sort$predictors)

#Print the predictors sorted by Mean Decrease in Gini
print(rf_imp_gini2.sort)
```

```{r }
#Plot Important Variables
#Variable Importance (Mean Decrease in Accuracy)
set.seed(123)
varImpPlot(rf_model2, type=1, main = "Variable Importance (Mean Decrease in Accuracy)")
```

```{r }
#install.packages("vip")
library(vip)
set.seed(123)
vip(rf_model2, type=1, num_features = 26L)
```

```{r }
#Variable Importance (Mean Decrease in Gini)
set.seed(123)
varImpPlot(rf_model2, type=2, main = "Variable Importance (Mean Decrease in Gini)")
```

```{r }
set.seed(123)
vip(rf_model2, type=2, num_features = 26L)
```

```{r }
#Test the model
rf_predict2 <- predict(rf_model2, test)

#Confusion Matrix and Statistics
rf_confusionMatrix_stats2 <- confusionMatrix(rf_predict2, test$shares_cat, mode = "everything", positive = "1")
print(rf_confusionMatrix_stats2)
```
