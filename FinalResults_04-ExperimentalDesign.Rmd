---
title: "FinalResults_04-ExperimentalDesign"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Predicting Online News Popularity based on Pre-publication Features

Final Results and Code


Step 4 - Experimental Design

```{r }
#Reload the data
pop_norm_subset <- read.csv(file = "pop_norm_subset.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, 
                        na.strings = c("", "NA"))

#Remove the index column
pop_norm_subset <- pop_norm_subset[2:28]
```

```{r }
#Change the categorical variables back to factor to conduct experimental design
pop_norm_subset$data_channel_is_entertainment <- as.factor(pop_norm_subset$data_channel_is_entertainment)
pop_norm_subset$data_channel_is_socmed <- as.factor(pop_norm_subset$data_channel_is_socmed)
pop_norm_subset$weekday_is_saturday <- as.factor(pop_norm_subset$weekday_is_saturday)
pop_norm_subset$weekday_is_sunday <- as.factor(pop_norm_subset$weekday_is_sunday)
pop_norm_subset$shares_cat <- as.factor(pop_norm_subset$shares_cat)
```

In this step, the processed data may be split into 70% training, 15% validation, and 15% test sets in order to tune the parameters of the models that will be studied; as well as split into training and test sets using 10-fold cross-validation to improve the performance of the models, and these results may be used to compare each model.

First, create train, test, and validation sets for tuning parameters

```{r }
#Index for 70% training set
set.seed(123)
train_index <- sample(1:nrow(pop_norm_subset), 0.7 * nrow(pop_norm_subset))

#Subset the data using the training index to create the training dataset
train.set <- pop_norm_subset[train_index,]

#The remaining data will be used for 15% validation and 15% test datasets
test_valid.set  <- pop_norm_subset[-train_index,]

#Index for 15% validation and 15% testing dataset
set.seed(123)
testvalid_index <- sample(1:nrow(test_valid.set), 0.5 * nrow(test_valid.set))

#Validation set
valid.set <- test_valid.set[testvalid_index,]

#Test set
test.set  <- test_valid.set[-testvalid_index,]
```

```{r }
#Check that the shares categories are balanced
summary(train.set$shares_cat)
```

```{r }
summary(valid.set$shares_cat)
```

```{r }
summary(test.set$shares_cat)
```

The popular and unpopular levels of shares are fairly balanced.


Second, create train and test sets using 10-fold cross-validation

```{r }
set.seed(123)
folds <- createFolds(pop_norm_subset$shares_cat)
str(folds)
for (f in folds){
  train <- pop_norm_subset[-f,]
  test <- pop_norm_subset[f,]
}
```

```{r }
#Check that the shares categories are balanced
summary(train$shares_cat)
```

```{r }
summary(test$shares_cat)
```

The popular and unpopular levels of shares are fairly balanced.

```{r }
#Save the dataframes
write.csv(train.set, "trainset.csv")
write.csv(valid.set, "validset.csv")
write.csv(test.set, "testset.csv")
write.csv(train, "train.csv")
write.csv(test, "test.csv")
```
